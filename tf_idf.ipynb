{"cells":[{"cell_type":"markdown","source":["Name: Bhavik Manwani\n"],"metadata":{"id":"WvY6VBrc33Gz"}},{"cell_type":"markdown","source":["Student_Id: 202318002"],"metadata":{"id":"qWrO3ncj4BVb"}},{"cell_type":"markdown","source":["# Imports"],"metadata":{"id":"ncDWEUaOz3B0"}},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":394,"status":"ok","timestamp":1706155815439,"user":{"displayName":"2023 18002","userId":"15071137639721912635"},"user_tz":-330},"id":"Om5RwG4Rx4ho"},"outputs":[],"source":["import sklearn\n","from sklearn.datasets import fetch_20newsgroups\n","import pandas as pd\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics.pairwise import cosine_similarity\n","import numpy as np\n"]},{"cell_type":"markdown","metadata":{"id":"h3r5zrnRxrpq"},"source":["#1. You need to implement a TF-IDF vectorizer to convert a collection of documents into TF-IDF vectors. You can use the sklearnâ€™s inbuild datase       fetch_20newsgroups."]},{"cell_type":"code","execution_count":22,"metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"4tdS12mGxrps","executionInfo":{"status":"ok","timestamp":1706155819991,"user_tz":-330,"elapsed":4146,"user":{"displayName":"2023 18002","userId":"15071137639721912635"}},"outputId":"03c2c2ce-8aea-4a3e-d8dd-25bcab6bf1c6"},"outputs":[{"output_type":"stream","name":"stdout","text":["TD-IDF vectors:  \n","  (0, 86416)\t0.14330464297977982\n","  (0, 35135)\t0.10188109676312235\n","  (0, 65968)\t0.10658183340971177\n","  (0, 114195)\t0.06002582888934523\n","  (0, 78809)\t0.06524029473980168\n","  (0, 76578)\t0.0752490171119318\n","  (0, 57203)\t0.16977226500364592\n","  (0, 67023)\t0.07965653370342658\n","  (0, 63238)\t0.09086750717799585\n","  (0, 95944)\t0.11792442679286105\n","  (0, 127721)\t0.0660283455431985\n","  (0, 109044)\t0.11811852219269026\n","  (0, 51651)\t0.10581100308545811\n","  (0, 83103)\t0.09633120317294654\n","  (0, 113755)\t0.1926949257821117\n","  (0, 73061)\t0.04662587301170703\n","  (0, 34131)\t0.09493746671845804\n","  (0, 101175)\t0.08899924936054199\n","  (0, 105907)\t0.10749912859686628\n","  (0, 35560)\t0.1446512460011004\n","  (0, 26070)\t0.10385185139503332\n","  (0, 108033)\t0.08197182211166716\n","  (0, 99619)\t0.06171903092868097\n","  (0, 48552)\t0.1263844988551673\n","  (0, 34943)\t0.18203649549572573\n","  :\t:\n","  (11313, 106061)\t0.11739285034416508\n","  (11313, 67469)\t0.07888902121089117\n","  (11313, 63763)\t0.11511167728184264\n","  (11313, 37359)\t0.16552340600580592\n","  (11313, 116769)\t0.08740758023936664\n","  (11313, 72166)\t0.10891263256743795\n","  (11313, 11390)\t0.14477754748280827\n","  (11313, 60694)\t0.08134974610767784\n","  (11313, 113581)\t0.0749042118526549\n","  (11313, 62582)\t0.0632144659864555\n","  (11313, 3411)\t0.07079755573089706\n","  (11313, 76233)\t0.06469398052315968\n","  (11313, 119441)\t0.060284105803626004\n","  (11313, 47916)\t0.049639180787655675\n","  (11313, 88185)\t0.14159511146179413\n","  (11313, 111466)\t0.08179695308516817\n","  (11313, 51651)\t0.10242810228694169\n","  (11313, 4605)\t0.06676826497088761\n","  (11313, 75888)\t0.020264179021749786\n","  (11313, 90192)\t0.021012136747188718\n","  (11313, 63970)\t0.037346306116846265\n","  (11313, 94962)\t0.03634515160466896\n","  (11313, 87451)\t0.037610885317695526\n","  (11313, 111094)\t0.020198023351223362\n","  (11313, 50455)\t0.057582965641085816\n"]}],"source":["# for vectorizing documents\n","def get_vec(data):\n","\n","    vec = TfidfVectorizer(stop_words = 'english')\n","\n","    #converting doc in vectors\n","    mat = vec.fit_transform(data)\n","    return mat\n","\n","data = fetch_20newsgroups(subset='train')\n","\n","vecs = get_vec(data['data'])\n","print('TD-IDF vectors:  ')\n","print(vecs)"]},{"cell_type":"markdown","metadata":{"id":"JRymAgbKxrpv"},"source":["#2. Create a function to calculate the cosine similarity between two TF-IDF vectors."]},{"cell_type":"code","execution_count":38,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uu01_eznxrpv","executionInfo":{"status":"ok","timestamp":1706156777971,"user_tz":-330,"elapsed":4210,"user":{"displayName":"2023 18002","userId":"15071137639721912635"}},"outputId":"6a6953e5-3ce7-485b-ed59-d987729b4e50"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Document 1:  From: mace@kilowatt.\n","\n","Document 2:  From: brow2812@mach1\n","\n","Cosine Similarity between docs:  0.002175\n"]}],"source":["tfidf_vecs = get_vec(data['data'])\n","\n","ind1 = np.random.randint(0, vecs.shape[0])\n","ind2 = np.random.randint(0, vecs.shape[0])\n","\n","print('\\nDocument 1: ', data['data'][ind1][:20])\n","print('\\nDocument 2: ', data['data'][ind2][:20])\n","\n","#cosine similarity between two documents\n","\n","csn_sim = cosine_similarity(vecs[ind1], vecs[ind2])\n","csn_sim = np.round(csn_sim[0][0], 6)\n","print('\\nCosine Similarity between docs: ', csn_sim)\n"]},{"cell_type":"markdown","metadata":{"id":"O50_ggjFxrpx"},"source":["#3. Implement a document similarity search function that takes a document as input and returns a list of documents ranked by their similarity to the input document."]},{"cell_type":"code","execution_count":41,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nu9vnrOkxrpx","executionInfo":{"status":"ok","timestamp":1706156843487,"user_tz":-330,"elapsed":4318,"user":{"displayName":"2023 18002","userId":"15071137639721912635"}},"outputId":"a72cab2c-25c9-4b84-8c3d-a6c88e1d2747"},"outputs":[{"output_type":"stream","name":"stdout","text":[" Similar Documents:\n"," ['From: jdenune@pandora.sdsu.edu' 'From: steveh@thor.isc-br.com ('\n"," 'From: doug@sun.sws.uiuc.edu (D' 'From: grady@netcom.com (1016/2'\n"," 'From: gmh@hpfcso.FC.HP.COM (Gr']\n"]}],"source":["# document similarity search function\n","\n","def cal_doc_sim(idx):\n","\n","    data = fetch_20newsgroups(subset='train')\n","    doc = data['data']\n","    dt = doc[idx]\n","\n","    doc.pop(idx)\n","    vec = TfidfVectorizer(stop_words = 'english')\n","    train = vec.fit_transform(doc)\n","    test = vec.transform([dt])\n","\n","    csn_sim = cosine_similarity(train, test)\n","    indices = np.arange(len(csn_sim)).astype('int')\n","\n","\n","    sim_index = np.argsort(csn_sim, axis=0).flatten()\n","    top5 = sim_index.argsort()[:-6:-1]\n","    result = [doc[i][:30] for i in top5]\n","\n","    return np.array (result)\n","\n","idx = np.random.randint(0, len(data['data']))\n","idx = cal_doc_sim(idx)\n","\n","print(\" Similar Documents:\\n\", idx)\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":0}